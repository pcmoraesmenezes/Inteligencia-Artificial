{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import (\n",
    "    ensemble,\n",
    "    preprocessing,\n",
    "    tree,\n",
    ")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    auc,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    ")\n",
    "\n",
    "from yellowbrick.classifier import (\n",
    "    ConfusionMatrix,\n",
    "    ROCAUC,\n",
    ")\n",
    "\n",
    "from yellowbrick.model_selection import (\n",
    "    LearningCurve,\n",
    ")\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_FILE = Path.cwd().parent\n",
    "DATA_FILE = ROOT_FILE / \"datasets\" / \"titanic3.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yellow Brick é uma biblioteca de visualização e diagnóstico para aprendizado de máquina que visa capacitar os usuários a visualizar os processos internos de seus modelos de aprendizado de máquina e permitir que eles tomem decisões mais informadas durante o processo de modelagem, facilitando a compreensão das forças e fraquezas de seus modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faça uma pergunta\n",
    "\n",
    "Essa corresponde a primeira etapa do processo de machine learning, onde você deve se perguntar o que deseja descobrir com os dados que possui. Para o exemplo do livro, será criado um modelo preditivo para responder uma pergunta: O indivíduo sobreviveu ou não ao naufrágio do Titanic? Terá-se como base os dados de passageiros do navio, como idade, sexo, classe social, etc.\n",
    "\n",
    "É uma pergunta de classificação, pois estamos fazendo a predição de um rotulo, que é a sobrevivência ou não do passageiro. Se fosse uma pergunta de regressão, seria algo como: Qual a idade do passageiro?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colete os dados\n",
    "\n",
    "A segunda etapa é a coleta dos dados, que pode ser feita de diversas formas, como por exemplo, através de um web crawler, que é um programa que navega pela web e coleta os dados de interesse. Pode ser feita pelo download de um dataset, como o do Kaggle, ou até mesmo através de uma API.\n",
    "\n",
    "Para o exemplo do livro, estou mostrando duas maneiras, uma através de uma URL e outra através do download de um dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\"https://hbiostat.org/data/repo/titanic3.csv\")\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "## OU\n",
    "\n",
    "df = pd.read_csv(DATA_FILE)\n",
    "\n",
    "df_orig = pd.read_csv(DATA_FILE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tem-se os seguintes dados:\n",
    "\n",
    "- **pclass**: Classe do passageiro (1 = primeira classe; 2 = segunda classe; 3 = terceira classe)\n",
    "\n",
    "- **survived**: Sobreviveu ou não (0 = Não; 1 = Sim)\n",
    "\n",
    "- **name**: Nome do passageiro\n",
    "\n",
    "- **sex**: Sexo do passageiro\n",
    "\n",
    "- **age**: Idade do passageiro\n",
    "\n",
    "- **sibsp**: Número de irmãos e cônjuges a bordo\n",
    "\n",
    "- **parch**: Número de pais e filhos a bordo\n",
    "\n",
    "- **ticket**: Número do ticket\n",
    "\n",
    "- **fare**: Tarifa do passageiro\n",
    "\n",
    "- **cabin**: Número da cabine\n",
    "\n",
    "- **embarked**: Porto de embarque (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "\n",
    "- **boat**: Bote salva-vidas\n",
    "\n",
    "- **body**: Número de identificação do corpo\n",
    "\n",
    "- **home.dest**: Destino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpe os dados\n",
    "\n",
    "A maioria dos modelo do scikit-learn exige que os dados sejam numéricos. Os modelos podem falhar caso recebam valores ausentes. Além disso alguns modelos podem ter melhores desempenhos se os dados estiverem padronizados.\n",
    "\n",
    "Podem também existir os chamados leaky features(dados que vazam informações). Essas variaveis contém informações sobre o futuro ou o resultado que se deseja prever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass         int64\n",
       "survived       int64\n",
       "name          object\n",
       "sex           object\n",
       "age          float64\n",
       "sibsp          int64\n",
       "parch          int64\n",
       "ticket        object\n",
       "fare         float64\n",
       "cabin         object\n",
       "embarked      object\n",
       "boat          object\n",
       "body         float64\n",
       "home.dest     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes # Verificando os tipos de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os tipos de dados mais comuns são:\n",
    "\n",
    "- **int64**: Números inteiros\n",
    "\n",
    "- **float64**: Números reais\n",
    "\n",
    "- **datetime64[ns]**: Data e hora\n",
    "\n",
    "- **object**: String, mas pode ser uma combinação entre strings e outros tipos\n",
    "\n",
    "No geral tipos inteiros não apresentam problemas. Tipos float podem apresentar problemas com valores ausentes. Tipos data e string deverão ser convertidos para números.\n",
    "\n",
    "Tipos string com baixa cardinalidade (poucos valores únicos) são chamados de colunas de categoria, é possível gerar colunas dummy (binárias) para cada valor único"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   pclass     1309 non-null   int64  \n",
      " 1   survived   1309 non-null   int64  \n",
      " 2   name       1309 non-null   object \n",
      " 3   sex        1309 non-null   object \n",
      " 4   age        1046 non-null   float64\n",
      " 5   sibsp      1309 non-null   int64  \n",
      " 6   parch      1309 non-null   int64  \n",
      " 7   ticket     1309 non-null   object \n",
      " 8   fare       1308 non-null   float64\n",
      " 9   cabin      295 non-null    object \n",
      " 10  embarked   1307 non-null   object \n",
      " 11  boat       486 non-null    object \n",
      " 12  body       121 non-null    float64\n",
      " 13  home.dest  745 non-null    object \n",
      "dtypes: float64(3), int64(4), object(7)\n",
      "memory usage: 143.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos 6 variaveis númericas, 7 variaveis categóricas e 1 variavel booleana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1309, 14)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # Verificando o tamanho do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1046.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1308.000000</td>\n",
       "      <td>121.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.294882</td>\n",
       "      <td>0.381971</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>0.498854</td>\n",
       "      <td>0.385027</td>\n",
       "      <td>33.295479</td>\n",
       "      <td>160.809917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.837836</td>\n",
       "      <td>0.486055</td>\n",
       "      <td>14.413493</td>\n",
       "      <td>1.041658</td>\n",
       "      <td>0.865560</td>\n",
       "      <td>51.758668</td>\n",
       "      <td>97.696922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>155.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.275000</td>\n",
       "      <td>256.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>328.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pclass     survived          age        sibsp        parch  \\\n",
       "count  1309.000000  1309.000000  1046.000000  1309.000000  1309.000000   \n",
       "mean      2.294882     0.381971    29.881138     0.498854     0.385027   \n",
       "std       0.837836     0.486055    14.413493     1.041658     0.865560   \n",
       "min       1.000000     0.000000     0.170000     0.000000     0.000000   \n",
       "25%       2.000000     0.000000    21.000000     0.000000     0.000000   \n",
       "50%       3.000000     0.000000    28.000000     0.000000     0.000000   \n",
       "75%       3.000000     1.000000    39.000000     1.000000     0.000000   \n",
       "max       3.000000     1.000000    80.000000     8.000000     9.000000   \n",
       "\n",
       "              fare        body  \n",
       "count  1308.000000  121.000000  \n",
       "mean     33.295479  160.809917  \n",
       "std      51.758668   97.696922  \n",
       "min       0.000000    1.000000  \n",
       "25%       7.895800   72.000000  \n",
       "50%      14.454200  155.000000  \n",
       "75%      31.275000  256.000000  \n",
       "max     512.329200  328.000000  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe() # Verificando as estatísticas do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.294882</td>\n",
       "      <td>0.381971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.837836</td>\n",
       "      <td>0.486055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pclass     survived\n",
       "count  1309.000000  1309.000000\n",
       "mean      2.294882     0.381971\n",
       "std       0.837836     0.486055\n",
       "min       1.000000     0.000000\n",
       "25%       2.000000     0.000000\n",
       "50%       3.000000     0.000000\n",
       "75%       3.000000     1.000000\n",
       "max       3.000000     1.000000"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().iloc[:, :2] # iloc é um método para selecionar \n",
    "# linhas e colunas por números inteiros. Neste caso, estamos\n",
    "# selecionando todas as linhas e as duas primeiras colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **count:**  quantidade de valores não nulos\n",
    "\n",
    "- **mean:** média dos valores\n",
    "\n",
    "- **std:** desvio padrão\n",
    "\n",
    "- **min:** valor mínimo\n",
    "\n",
    "- **25%:** primeiro quartil\n",
    "\n",
    "- **50%:** segundo quartil (mediana)\n",
    "\n",
    "- **75%:** terceiro quartil\n",
    "\n",
    "- **max:** valor máximo\n",
    "\n",
    "Count é interessa para identificar valores ausentes. A mediana é mais robusta que a média, pois não é afetada por outliers.\n",
    "\n",
    "Min e máx são importantes para identificar outliers. O desvio padrão é uma medida de dispersão, quanto maior o desvio padrão, maior a dispersão dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "df.isnull() # retorna um dataframe com valores booleanos, onde True indica que o valor é nulo\n",
    "\n",
    "df.isnull().sum() # retorna a soma dos valores nulos de cada coluna\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass          0\n",
       "survived        0\n",
       "name            0\n",
       "sex             0\n",
       "age           263\n",
       "sibsp           0\n",
       "parch           0\n",
       "ticket          0\n",
       "fare            1\n",
       "cabin        1014\n",
       "embarked        2\n",
       "boat          823\n",
       "body         1188\n",
       "home.dest     564\n",
       "dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() # Verificando a quantidade de valores nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "df.isnull().mean() # Verificando a porcentagem de valores nulos\n",
    "\n",
    "```\n",
    "\n",
    "Útil para identificar colunas com muitos valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     1\n",
       "2     2\n",
       "3     1\n",
       "4     2\n",
       "5     1\n",
       "6     1\n",
       "7     2\n",
       "8     1\n",
       "9     2\n",
       "10    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum(axis=1).loc[:10] # Verificando a quantidade de valores nulos por linha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A coluna body deve ser removida pois contém muitos valores nulos e pode ser considerada uma leaky feature (informa que o passageiro morreu).\n",
    "\n",
    "A coluna boat também deve ser removida pois contém muitos valores nulos e pode ser considerada uma leaky feature (informa que o passageiro sobreviveu).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    True\n",
       "1    True\n",
       "2    True\n",
       "3    True\n",
       "4    True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = df.isnull().any(axis = 1) # Criando uma máscara para selecionar as linhas com valores nulos\n",
    "# any é um método que retorna True se qualquer elemento do eixo for True\n",
    "mask.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      NaN\n",
       "1      NaN\n",
       "2      NaN\n",
       "3    135.0\n",
       "4      NaN\n",
       "Name: body, dtype: float64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[mask].body.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex\n",
       "male      843\n",
       "female    466\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sex.value_counts() # Verificando a quantidade de valores por categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "embarked\n",
       "S      914\n",
       "C      270\n",
       "Q      123\n",
       "NaN      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.embarked.value_counts(dropna=False) # Verificando a quantidade de valores por categoria, incluindo os valores nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos 2 valores nulos na coluna embarked, podemos substituir pela moda (valor mais frequente), remover a linha, ou criar um dummy, ou então substituir pela média."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando os atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Allen, Miss. Elisabeth Walton\n",
       "1    Allison, Master. Hudson Trevor\n",
       "2      Allison, Miss. Helen Loraine\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = df['name']\n",
    "# ou\n",
    "name = df.name\n",
    "name.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\n",
    "    columns=[\n",
    "        'name',\n",
    "        'ticket',\n",
    "        'home.dest',\n",
    "        'boat',\n",
    "        'body',\n",
    "        'cabin',\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliza-se o método `drop` para remover linhas ou colunas, o padrão é remover linhas, para remover colunas, deve-se passar o parâmetro `axis=1`.\n",
    "\n",
    "Remove-se, então: name, ticket, cabin, boat, body e home.dest\n",
    "\n",
    "boat e body são leaky features, pois informam se o passageiro sobreviveu ou não\n",
    "\n",
    "name, ticket e cabin são colunas de alta cardinalidade, ou seja, possuem muitos valores únicos, o que pode dificultar o aprendizado do modelo\n",
    "\n",
    "home.dest é uma coluna de baixa cardinalidade, mas não é relevante para o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   pclass    1309 non-null   int64  \n",
      " 1   survived  1309 non-null   int64  \n",
      " 2   sex       1309 non-null   object \n",
      " 3   age       1046 non-null   float64\n",
      " 4   sibsp     1309 non-null   int64  \n",
      " 5   parch     1309 non-null   int64  \n",
      " 6   fare      1308 non-null   float64\n",
      " 7   embarked  1307 non-null   object \n",
      "dtypes: float64(2), int64(4), object(2)\n",
      "memory usage: 81.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   pclass      1309 non-null   int64  \n",
      " 1   survived    1309 non-null   int64  \n",
      " 2   age         1046 non-null   float64\n",
      " 3   sibsp       1309 non-null   int64  \n",
      " 4   parch       1309 non-null   int64  \n",
      " 5   fare        1308 non-null   float64\n",
      " 6   sex_female  1309 non-null   bool   \n",
      " 7   sex_male    1309 non-null   bool   \n",
      " 8   embarked_C  1309 non-null   bool   \n",
      " 9   embarked_Q  1309 non-null   bool   \n",
      " 10  embarked_S  1309 non-null   bool   \n",
      "dtypes: bool(5), float64(2), int64(4)\n",
      "memory usage: 67.9 KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.get_dummies(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliza-se `pd.get_dummies` para criar colunas dummy para as colunas categóricas\n",
    "\n",
    "Essas colunas dummy são binárias, ou seja, possuem apenas 2 valores, 0 ou 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='sex_male')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove-se a coluna sex_male, pois ela é inversa a coluna sex_female. Se o valor de uma for 0, o valor da outra será 1 e vice-versa. Esse tipo de relação é chamada de correlação perfeita negativa. Essas relações podem causar problemas no modelo, pois o modelo pode entender que uma coluna é mais importante que a outra, quando na verdade elas são iguais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pclass', 'survived', 'age', 'sibsp', 'parch', 'fare', 'sex_female',\n",
       "       'embarked_C', 'embarked_Q', 'embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df, drop_first=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passando o parâmetro `drop_first=True` para `pd.get_dummies`, a primeira coluna dummy será removida, evitando assim a correlação perfeita negativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='survived')\n",
    "y = df.survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "X = df.drop(columns='survived')\n",
    "y = df['survived']\n",
    "```\n",
    "\n",
    "X é um dataframe com todas as colunas, exceto a coluna survived\n",
    "\n",
    "y é uma série com a coluna survived\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando as amostras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método `train_test_split` separa os dados em amostras de treino e teste. O parâmetro `test_size` define a porcentagem de dados que serão separados para teste, o padrão é 25%. Para o exemplo está sendo utilizado 30%, o que quer dizer que 70% dos dados são para treino e 30% para teste.\n",
    "\n",
    "O parametro `random_state` define a semente do gerador de números aleatórios, isso garante que a separação dos dados seja sempre a mesma, ou seja, sempre que o código for executado, os mesmos dados serão separados para treino e teste.\n",
    "\n",
    "`X_train` é um dataframe contendo 70% dos dados de X\n",
    "\n",
    "`X_test` é um dataframe contendo 30% dos dados de X\n",
    "\n",
    "`y_train` é uma série contendo 70% dos dados de y\n",
    "\n",
    "`y_test` é uma série contendo 30% dos dados de y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Faça a imputação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   pclass      1309 non-null   int64  \n",
      " 1   survived    1309 non-null   int64  \n",
      " 2   age         1046 non-null   float64\n",
      " 3   sibsp       1309 non-null   int64  \n",
      " 4   parch       1309 non-null   int64  \n",
      " 5   fare        1308 non-null   float64\n",
      " 6   sex_female  1309 non-null   bool   \n",
      " 7   embarked_C  1309 non-null   bool   \n",
      " 8   embarked_Q  1309 non-null   bool   \n",
      " 9   embarked_S  1309 non-null   bool   \n",
      "dtypes: bool(4), float64(2), int64(4)\n",
      "memory usage: 66.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\n",
    "    'pclass',\n",
    "    'age',\n",
    "    'sibsp',\n",
    "    'parch',\n",
    "    'fare',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O numero de valores nulos no X_train é: 0\n",
      "O numero de valores nulos no X_test é: 0\n"
     ]
    }
   ],
   "source": [
    "imputer = impute.IterativeImputer()\n",
    "\n",
    "imputed = imputer.fit_transform(\n",
    "    X_train[num_cols]\n",
    ")\n",
    "X_train.loc[:, num_cols] = imputed\n",
    "\n",
    "imputed = imputer.transform(\n",
    "    X_test[num_cols]\n",
    ")\n",
    "X_test.loc[:, num_cols] = imputed\n",
    "\n",
    "nan_values_x_train = X_train.isnull().sum()\n",
    "nan_values_x_test = X_test.isnull().sum()\n",
    "\n",
    "print(f'O numero de valores nulos no X_train é: {nan_values_x_train.sum()}'\\\n",
    "      f'\\nO numero de valores nulos no X_test é: {nan_values_x_test.sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma das formas de lidar com esses valores nulos é através da imputação, que é a substituição dos valores nulos por outros valores. Foi utilizada a biblioteca `sklearn.impute` para fazer a imputação.\n",
    "\n",
    "Inicialmente cria-se uma variavel `num_cols`  com as colunas numéricas.\n",
    "\n",
    "Em seguida cria-se `imputer` com o método `impute.IterativeImputer()`, ou seja `imputer` é um objeto da classe `IterativeImputer`.\n",
    "\n",
    "Cria-se em sequência a variavel `imputed` através `imputer.fit_transform(X_tra[num_cols]`, ou seja, `imputed` é um array numpy com os valores imputados.\n",
    "\n",
    "Em sequência é feita a indexação de `imputed` para `X_train[num_cols]` e `X_test[num_cols]`, ou seja, os valores imputados são atribuidos a `X_train[num_cols]` e `X_test[num_cols]`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O numero de valores nulos no X_train é: 0\n",
      "O numero de valores nulos no X_test é: 0\n"
     ]
    }
   ],
   "source": [
    "meds = X_train.median()\n",
    "\n",
    "X_train = X_train.fillna(meds)\n",
    "X_test = X_test.fillna(meds)\n",
    "\n",
    "nan_values_x_train = X_train.isnull().sum()\n",
    "nan_values_x_test = X_test.isnull().sum()\n",
    "\n",
    "print(f'O numero de valores nulos no X_train é: {nan_values_x_train.sum()}'\\\n",
    "        f'\\nO numero de valores nulos no X_test é: {nan_values_x_test.sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De modo semelhante pode-se imputar valores utilizando a mediana por exemplo.\n",
    "\n",
    "Cria-se uma variavel chamada `meds`, ela recebe a mediana de `X_train`, e em sequência utiliza-se o método `fillna` para substituir os valores nulos de `X_train` e `X_test` pela mediana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "cols = ['pclass', 'age', 'sibsp', 'parch', 'fare', 'sex_female', 'embarked_C',\n",
    "   'embarked_Q', 'embarked_S']\n",
    "sca = preprocessing.StandardScaler()\n",
    "X_train = sca.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=cols)\n",
    "X_test = sca.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns=cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refatore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweaky_titanic (df):\n",
    "    df.drop(\n",
    "        columns=[\n",
    "            'name',\n",
    "            'ticket',\n",
    "            'home.dest',\n",
    "            'boat',\n",
    "            'body',\n",
    "            'cabin',\n",
    "        ],\n",
    "    ).pipe(pd.get_dummies, drop_first=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `.pipe` permite encadear funções, ou seja, o resultado de uma função é passado como parâmetro para a próxima função.\n",
    "\n",
    "O parâmetro `drop_first=True` é passado para `pd.get_dummies` através de `.pipe`, evitando assim a correlação perfeita negativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma breve explicação sobre a função `tweaky_titanic` :\n",
    "\n",
    "```python\n",
    "\n",
    "def tweaky_titanic (df):\n",
    "    df.drop(\n",
    "        columns=[\n",
    "            'name',\n",
    "            'ticket',\n",
    "            'home.dest',\n",
    "            'boat',\n",
    "            'body',\n",
    "            'cabin',\n",
    "        ],\n",
    "    ).pipe(pd.get_dummies, drop_first=True)\n",
    "    return df\n",
    "\n",
    "```\n",
    "\n",
    "A função irá receber um data frame como parâmetro, e em seguida irá remover as colunas name, ticket, home.dest, boat, body e cabin. Em seguida irá criar colunas dummy para as colunas categóricas, e por fim irá retornar o data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "def get_train_test_X_y (\n",
    "        df, y_col, size = 0.3, std_cols = None\n",
    "):\n",
    "    y = df[y_col]\n",
    "    X = df.drop(columns=y_col)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=size,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    cols = X.columns\n",
    "    num_cols = [\n",
    "        'pclass',\n",
    "        'age',\n",
    "        'sibsp',\n",
    "        'parch',\n",
    "        'fare',\n",
    "    ]\n",
    "    \n",
    "    fi = impute.IterativeImputer()\n",
    "    X_train.loc[:, num_cols] = fi.fit_transform(\n",
    "        X_train[num_cols]\n",
    "    )\n",
    "\n",
    "    X_test.loc[:, num_cols] = fi.transform(\n",
    "        X_test[num_cols]\n",
    "    )\n",
    "\n",
    "    if std_cols:\n",
    "        std = preprocessing.StandardScaler()\n",
    "        X_train.loc[:, std_cols] = std.fit_transform(\n",
    "            X_train[std_cols]\n",
    "        )\n",
    "\n",
    "        X_test.loc[:, std_cols] = std.transform(\n",
    "            X_test[std_cols]\n",
    "        )\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicação sobre a função `get_train_text_X_y` :\n",
    "\n",
    "```python\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "def get_train_test_X_y (\n",
    "        df, y_col, size = 0.3, std_cols = None\n",
    "):\n",
    "    y = df[y_col]\n",
    "    X = df.drop(columns=y_col)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=size,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    cols = X.columns\n",
    "    num_cols = [\n",
    "        'pclass',\n",
    "        'age',\n",
    "        'sibsp',\n",
    "        'parch',\n",
    "        'fare',\n",
    "    ]\n",
    "    \n",
    "    fi = impute.IterativeImputer()\n",
    "    X_train.loc[:, num_cols] = fi.fit_transform(\n",
    "        X_train[num_cols]\n",
    "    )\n",
    "\n",
    "    X_test.loc[:, num_cols] = fi.transform(\n",
    "        X_test[num_cols]\n",
    "    )\n",
    "\n",
    "    if std_cols:\n",
    "        std = preprocessing.StandardScaler()\n",
    "        X_train.loc[:, std_cols] = std.fit_transform(\n",
    "            X_train[std_cols]\n",
    "        )\n",
    "\n",
    "        X_test.loc[:, std_cols] = std.transform(\n",
    "            X_test[std_cols]\n",
    "        )\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "```\n",
    "\n",
    "Inicia-se importando a classe `IterativeImputer` da biblioteca `sklearn.experimental`, essa classe permite fazer a imputação dos dados.\n",
    "\n",
    "A função recebe como parâmetro um data frame, o nome da coluna alvo, o tamanho da amostra de teste, e uma lista com as colunas que serão padronizadas.\n",
    "\n",
    "Em seguida é feita a separação dos dados em amostras de treino e teste.\n",
    "\n",
    "Em seguida é criada uma lista com as colunas numéricas.\n",
    "\n",
    "Em seguida é criado um objeto da classe `IterativeImputer` e em seguida é feita a imputação dos dados de treino e teste.\n",
    "\n",
    "Em seguida é feita a padronização dos dados de treino e teste.\n",
    "\n",
    "A padronização é feita através da classe `StandardScaler` da biblioteca `sklearn.preprocessing`. Ela so é feita se o parâmetro `std_cols` for diferente de `None`.\n",
    "\n",
    "Por fim a função retorna os dados de treino e teste.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti_df = tweaky_titanic(df_orig)\n",
    "\n",
    "std_cols = \"pclass, age, sibsp, parch, fare\".split(\", \")\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test_X_y(\n",
    "    ti_df, \"survived\", std_cols=std_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicação do código acima:\n",
    "\n",
    "```python\n",
    "\n",
    "ti_df = tweaky_titanic(df_orig)\n",
    "\n",
    "std_cols = \"pclass, age, sibsp, parch, fare\".split(\", \")\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test_X_y(\n",
    "    ti_df, \"survived\", std_cols=std_cols\n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "A variavel `ti_df` recebe o resultado da função `tweaky_titanic` que recebe como parâmetro o data frame original.\n",
    "\n",
    "A variavel `std_cols` recebe uma lista com as colunas que serão padronizadas.\n",
    "\n",
    "Em seguida as variaveis `X_train, X_test, y_train, y_test` recebem o resultado da função `get_train_test_X_y` que recebe como parâmetro o data frame `ti_df`, o nome da coluna alvo, e a lista com as colunas que serão padronizadas.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5699745547073791"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "bm = DummyClassifier()\n",
    "bm.fit(X_train, y_train)\n",
    "bm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicação do código acima:\n",
    "\n",
    "```python\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "bm = DummyClassifier()\n",
    "bm.fit(X_train, y_train)\n",
    "bm.score(X_test, y_test)\n",
    "\n",
    "```\n",
    "\n",
    "A variavel `bm` recebe um objeto da classe `DummyClassifier` da biblioteca `sklearn.dummy`. Essa classe cria um modelo que faz previsões aleatórias.\n",
    "\n",
    "Em seguida é feito o treinamento do modelo através do método `fit` e em seguida é feita a previsão através do método `score`.\n",
    "\n",
    "O resultado é 0.55, ou seja, o modelo acerta 55% das previsões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcmoraes/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.precision_score(\n",
    "    y_test, bm.predict(X_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicação do código acima:\n",
    "\n",
    "```python\n",
    "\n",
    "from sklearn import metrics\n",
    "metrics.precision_score(\n",
    "    y_test, bm.predict(X_test)\n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "A função `precision_score` da biblioteca `sklearn.metrics` calcula a precisão do modelo, ou seja, a quantidade de previsões corretas dividido pela quantidade de previsões totais.\n",
    "\n",
    "O resultado é 0.55, ou seja, o modelo acerta 55% das previsões.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
